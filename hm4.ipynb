{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3b0e3c-998c-410a-b6d7-657874aa8983",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91ba068d-d2e0-49f8-95ff-d138a374191b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sofya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import nltk \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e37a556-70c0-46fd-adb6-b1ff269a45dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvach = open('2ch_corpus.txt', encoding='utf-8').read()\n",
    "\n",
    "def normalize(text):\n",
    "    normalized_text = [word.text.strip(punctuation) for word \\\n",
    "                                                            in razdel_tokenize(text)]\n",
    "    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n",
    "    return normalized_text\n",
    "\n",
    "norm_dvach = normalize(dvach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "df14d87a-f31b-4933-a755-3ef542da8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def ngrammer(tokens, n=2):\n",
    "    ngrams = []\n",
    "    for i in range(0,len(tokens)-n+1):\n",
    "        ngrams.append(' '.join(tokens[i:i+n]))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6f008fda-3e60-43f5-bf53-b28dab281cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_dvach = [['<start>'] + ['<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(dvach[:5000000])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "49c00378-0c35-4d41-a281-346663d21c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams_dvach = Counter()\n",
    "bigrams_dvach = Counter()\n",
    "trigrams_dvach = Counter()\n",
    "\n",
    "for sentence in sentences_dvach:\n",
    "    unigrams_dvach.update(sentence)\n",
    "    bigrams_dvach.update(ngrammer(sentence))\n",
    "    trigrams_dvach.update(ngrammer(sentence, n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb082aad-7cbe-4123-b860-bafa0868c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7db6bd12-7310-4dc8-b18a-5a2bde6eb8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dvach = lil_matrix((len(bigrams_dvach), \n",
    "                         len(unigrams_dvach)))\n",
    "\n",
    "id2bigr_dvach = list(bigrams_dvach)\n",
    "bigr2id_dvach = {bigram:i for i, bigram in enumerate(id2bigr_dvach)}\n",
    "id2word_dvach = list(unigrams_dvach)\n",
    "word2id_dvach = {word:i for i, word in enumerate(id2word_dvach)}\n",
    "\n",
    "\n",
    "\n",
    "for ngram in trigrams_dvach:\n",
    "    word1, word2, word3 = ngram.split()\n",
    "    bigram = ' '.join([word1, word2])\n",
    "    matrix_dvach[bigr2id_dvach[bigram], word2id_dvach[word3]] =  (trigrams_dvach[ngram]/\n",
    "                                                                     bigrams_dvach[bigram])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "958dc5fd-8804-4f5a-a3ca-cbf15ae13102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(matrix, id2word, id2bigr, bigr2id, n=100, start='<start> <start>'):\n",
    "    text = []\n",
    "    current_idx = bigr2id[start]\n",
    "    \n",
    "    for i in range(n):\n",
    "        chosen = np.random.choice(matrix.shape[1], p=matrix[current_idx].toarray()[0])\n",
    "        text.append(id2word[chosen]) \n",
    "        chosen_bg = bigr2id[' '.join([id2bigr[current_idx].split()[1], id2word[chosen]])]\n",
    "        if id2word[chosen] == '<end>':\n",
    "            chosen_bg = bigr2id['<start> <start>']\n",
    "        \n",
    "        current_idx = chosen_bg\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5303545e-4664-48a9-bd03-50074cd6b6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "их чувства охраняют \n",
      " как фейк на это есть дача бабла и потом бы резко повернулся и посмотрел 4 серии \n",
      " джве недели не особо хотел \n",
      " я же хиккан \n",
      " до них их придут и им не будет поработать над нижней челюстью говно хз как раньше было веселее в таких вещах логика не работает \n",
      " а много ли у кибернетического тела майора пиздень \n",
      " читать стоит первую книгу если сериал и лига 1 \n",
      " отсутствие пробивных социоскиллов и как в нее записался \n",
      " по идее должны быть типа путешествие во времени эффект бабочки намного популярнее чем праймер \n",
      " а\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, id2bigr_dvach, bigr2id_dvach).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a906bfd8-63fb-4ac5-85c2-07664e7b4cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "то есть понятно что я тоже не проблема для нашего общества \n",
      " так что сейчас эта бандура в музее концерна калашников \n",
      " я так курсовую за сутки в лимит \n",
      " всё остальное гавно для быдла \n",
      " а именно короткий список принимая это соглашения вы передаете майкрософт право по своему вкусу \n",
      " и я не его слабость \n",
      " скорпиона в шахматы обыграл \n",
      " вера кичанова врывается в этот тред считал себя извращугой \n",
      " 28 знание натрия он никогда от тебя нельзя заводить потомство не было в 96 ом \n",
      " 9 уровень а ничего \n",
      " а бить за плохую игру \n",
      " мальчик\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, id2bigr_dvach, bigr2id_dvach).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d48437cc-8175-4709-a050-ee343c64cf85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ан i ме кстати лучше вытиран i в \n",
      " к слову я сторонник теории что появится бандл с четырьмя флотами на мою харизматичность я абсолютно не имею сам иногда удивляюсь как можно быть аристократом но писать это еще даже не знаю что там между ними \n",
      " от атак бетельгейзе магия не помогает в хозяйстве вещь полезная и интересная хуйня стелсы забыл как на двух хуях стульях равноправии и патриархате \n",
      " ну то же самое но бесплатно не \n",
      " ты дурачек обычный город в котором ещё был напарник-эльф учил его бою на мечах \n",
      " охуенные ощущения особенно в кривых руках \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(generate(matrix_dvach, id2word_dvach, id2bigr_dvach, bigr2id_dvach).replace('<end>', '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62baaca1-02ee-482e-a38f-3291e5fa5b71",
   "metadata": {},
   "source": [
    "Перплексия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "52e3d84c-8260-4622-a1a4-feca684e3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Богатым родителям легче обеспечить своего потомка хорошим образованием и прочим.\n",
      "Но вопрос - откуда взялись богатые родители?\n",
      "(Опустим вариант что у них были свои богатые родители и т. д. до начала времен).Опять же, понятие богатства разнится в больших пределах.\n",
      "Для кого-то богатство это дворцы, для кого-то - возможность жрать каждый день и иметь свою крышу над головой.\n",
      "Многие упускают тот факт, что богатые родители дают своим детям не только деньги.\n",
      "Они дают им правильное отношение к деньгами, к жизни вообще, к выставлению жизненных приоритетов.\n",
      "Это к вопросу о том, почему например на западе есть поколения богатых людей, а у нас внезапно разбогатевшие родители не гарантия того, что сыночка не проебет все богатство в первые же годы наследства.\n",
      "Богатый - тот, кто понимает цену денег, умеет с ними обращаться.\n",
      "Дай нищеброду миллион, он так и останется нищебродом, просрет и пробухает все до нуля, а потом снова начнет ныть, что его богатые притесняют.\n",
      "Вот и ответ, почему русские сидят на жопе и ноют, что у них нет денег.\n",
      "Кто о чем, русский о хуях.\n",
      "Тебя никто не заставляет.\n",
      "Есть техзадание, есть оплата за выполнение.\n",
      "Хочешь - берись, хочешь, хуй соси или что там тебе привычнее.\n",
      "30к за пару дней неспешной работы за компом ему блядь мало.\n",
      "У людей за месяц бывает зарплата меньше, где приходится 8 часов 5 дней в неделю говно чистить, а этому снобу 30к за то, что он умеет мало.\n",
      "Пососатель, что сам умеешь, что за профессия?\n",
      ">Но вопрос - откуда взялись богатые родители?И здесь ты пытаешься судить детей за грехи отцов.\n",
      "У тебя логическое противоречие - либо ты говоришь, что человек \"сам виноват\" и \"сам может добиться\", либо начинаешь сравнивать не только двух человек, а ещё и их родителей - на достижения которых он до своего рождения вообще никак не мог повлиять.>Дай нищеброду миллион, он так и останется нищебродом, просрет и пробухает все до нуля Старая сказка.\n",
      "Спиздани нам что-нибудь ещё про рыбу и удочку.\n",
      "Просто подожди лет до 30-35 и тебе станет похуй.\n"
     ]
    }
   ],
   "source": [
    "#предложения для проверки \n",
    "for sentence in sent_tokenize(dvach[5000019:5001999]):\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "acec30dc-3507-458e-ad4a-8950e7289a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_join_proba_markov_assumption(phrase, bigram_counts, trigram_counts):\n",
    "    prob = 0\n",
    "    tokens = normalize(phrase)\n",
    "    for ngram in ngrammer(['<start>'] + ['<start>'] + tokens + ['<end>'], n=3):\n",
    "        word1, word2, word3 = ngram.split()\n",
    "        bigram = ' '.join([word1, word2])\n",
    "        if bigram in bigram_counts and ngram in trigram_counts:\n",
    "            prob += np.log(trigram_counts[ngram]/bigram_counts[bigram])\n",
    "        else:\n",
    "            prob += np.log(2e-5)\n",
    "    \n",
    "    return prob, len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "35d60ea9-c9a9-4517-9ca1-e2725bb66a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(logp, N):\n",
    "    return np.exp((-1/N) * logp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4128300e-7573-4e0f-8ded-c91bb3460664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57784.17236838252\n",
      "47335.29080475254\n",
      "27208.79534548336\n",
      "44452.36351473787\n",
      "26160.760529619307\n",
      "73584.56844034744\n",
      "17740.210292553027\n",
      "24776.570930566675\n",
      "30895.987265404958\n",
      "2624.8350359154606\n",
      "8753.768317054797\n",
      "578.2721290816614\n",
      "126694.24823267621\n",
      "48469.40788870388\n",
      "11944.85723405921\n",
      "11243.041514235512\n",
      "234558.6392717706\n",
      "48916.572867092116\n",
      "20095.838316736903\n",
      "193348.6993246414\n",
      "89700.38372651335\n",
      "среднее: 54612.72777858708\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for sentence in sent_tokenize(dvach[5000019:5001999]):\n",
    "    prob, N = compute_join_proba_markov_assumption(sentence, bigrams_dvach, trigrams_dvach)\n",
    "    sum += perplexity(prob, N)\n",
    "    print(perplexity(prob, N))\n",
    "\n",
    "print(\"среднее:\", sum/len(sent_tokenize(dvach[5000019:5001999])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c298b6d0-fc35-4929-b4d0-e6763b992604",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
